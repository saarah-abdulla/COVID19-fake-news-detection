{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-fourth",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import matplotlib.pyplot as plt\n",
    "import wandb\n",
    "\n",
    "from transformers import AlbertTokenizer, TFAlbertModel\n",
    "import numpy as np\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "arabic-bracket",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing and data loading functions\n",
    "\n",
    "\"\"\"\n",
    "Loading dataset from excel\n",
    "\n",
    "Return:\n",
    "    Data file read from Pandas    \n",
    "\"\"\"\n",
    "\n",
    "train = pd.read_excel('../dataset/Project_Datasets/Constraint_English_Train.xlsx')\n",
    "val = pd.read_excel('../dataset/Project_Datasets/Constraint_English_Val.xlsx')\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Clean Text function\n",
    "\n",
    "Args:\n",
    "    string: Each line of tweets from the excel file\n",
    "    \n",
    "Output:\n",
    "    The processed tweets according to cleanText criteria\n",
    "\"\"\"\n",
    "\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "def cleanText(string):\n",
    "    text = string.lower().split() # change all the sentences to lower case\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r\"http(\\S)+\",' ',text) # removes link    \n",
    "    text = re.sub(r\"www(\\S)+\",' ',text) # removes link\n",
    "    text = text.replace('&amp',' ') # remove &amp and replace with space\n",
    "    text = re.sub(r\"&\",' and ',text) # replace the symbol \"&\" with the word \"and\"\n",
    "    text = re.sub(r\"[^0-9a-zA-Z]+\",' ',text) # removes all except regex (including emojis)\n",
    "    text = text.split()\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Data loader function\n",
    "\n",
    "Args:\n",
    "    input_data: Dataset excel file read from Pandas\n",
    "    \n",
    "Output: \n",
    "    List of lists, each list is of [tweets, label]\n",
    "\"\"\"  \n",
    "\n",
    "def load_data(input_data):\n",
    "    output = []\n",
    "    for index, row in input_data.iterrows():\n",
    "        tweets = cleanText(row[1])\n",
    "        label = row[2]\n",
    "        if label == \"real\":\n",
    "            label_out = 1\n",
    "        else:\n",
    "            label_out = 0\n",
    "        output.append([tweets, label_out])\n",
    "    return output\n",
    "\n",
    "\n",
    "print(load_data(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liberal-sampling",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving post-processed Training output\n",
    "\n",
    "\"\"\"\n",
    "This code will save the post processed training dataset into a text file\n",
    "\n",
    "Output:\n",
    "    .txt file with each line as an input from the excel in the format of [tweet, label]\n",
    "\"\"\"\n",
    "\n",
    "post_processed = load_data(train)\n",
    "\n",
    "with open('post_processed_output.txt', 'w') as f:\n",
    "    for item in post_processed:\n",
    "        f.write(\"%s - %d\\n\" %(item[0], item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "based-winner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Train, Val data in Pandas.DataFrame format\n",
    "\n",
    "train_data = load_data(train)\n",
    "train_df = pd.DataFrame(train_data)\n",
    "train_df.columns = [\"tweets\", \"labels\"]\n",
    "\n",
    "val_data = load_data(val)\n",
    "val_df = pd.DataFrame(val_data)\n",
    "val_df.columns = [\"tweets\", \"labels\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-snapshot",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For hyperparameter tuning\n",
    "# This cell should be skipped if the intention is not for tuning hyperparameters\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "model_args.eval_batch_size = 8\n",
    "model_args.evaluate_during_training = True\n",
    "model_args.evaluate_during_training_silent = False\n",
    "model_args.evaluate_during_training_steps = 1000\n",
    "model_args.learning_rate = 4e-4\n",
    "model_args.manual_seed = 4\n",
    "model_args.max_seq_length = 256\n",
    "model_args.multiprocessing_chunksize = 5000\n",
    "model_args.no_cache = True\n",
    "model_args.no_save = True\n",
    "model_args.num_train_epochs = 10\n",
    "model_args.overwrite_output_dir = True\n",
    "model_args.reprocess_input_data = True\n",
    "model_args.train_batch_size = 16\n",
    "model_args.gradient_accumulation_steps = 2\n",
    "model_args.train_custom_parameters_only = False\n",
    "model_args.wandb_project = \"albert\"\n",
    "\n",
    "\"\"\"\n",
    "For weights & bias (wandb) configuration and running\n",
    "\n",
    "Required:\n",
    "    sweep_config: Configuration for the hyperparameters to be tuned\n",
    "    wandb.login(): For connecting to the wandb website with the credentials\n",
    "    sweep_id: configure which project the sweep is running for\n",
    "\"\"\"\n",
    "\n",
    "sweep_config = {\n",
    "    \"name\": \"batch-size-test\",\n",
    "    \"method\": \"bayes\",\n",
    "    \"metric\": {\"name\": \"accuracy\", \"goal\": \"maximize\"},\n",
    "    \"parameters\": {\n",
    "        \"num_train_epochs\": {\"min\": 30, \"max\": 60},\n",
    "        \"learning_rate\": {\"min\": 0, \"max\": 1e-3},\n",
    "        \"max_seq_length\": {\"values\": [512, 256, 128, 64]},\n",
    "        \"batch_size\": {\"values\": [256, 128, 64]}\n",
    "    },\n",
    "    \"early_terminate\": {\"type\": \"hyperband\", \"min_iter\": 6,},\n",
    "}\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "sweep_id = wandb.sweep(sweep_config, project=\"albert\")\n",
    "\n",
    "\"\"\"\n",
    "This function is used by wandb agent for sweep hyperparameter tuning\n",
    "\n",
    "Parameters:\n",
    "    Model: specify which model to use (eg. albert, bert)\n",
    "    Version: specify which version of the model (eg. albert-base-v2)\n",
    "    wandb.config: specify the config (can be from a external config file\n",
    "                                      or the sweep_config declared earlier on)\n",
    "\"\"\"\n",
    "def train():\n",
    "\n",
    "    # Initialize a new wandb run\n",
    "    wandb.init() \n",
    "    \n",
    "    model = ClassificationModel(\n",
    "        'albert', \n",
    "        'albert-base-v2', \n",
    "        num_labels=2, \n",
    "        use_cuda=True, \n",
    "        args=model_args,\n",
    "        sweep_config=wandb.config\n",
    "    )\n",
    "    \n",
    "    model.train_model(\n",
    "        train_df,\n",
    "        eval_df=val_df,\n",
    "        accuracy=lambda truth, predictions: accuracy_score(\n",
    "            truth, [round(p) for p in predictions]\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Sync wandb\n",
    "    wandb.join()\n",
    "\n",
    "\"\"\"\n",
    "A worker agent that takes in sweep_id and train() function\n",
    "to start the sweep and to be monitored in wandb website for results\n",
    "\"\"\"\n",
    "wandb.agent(sweep_id, train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For training the Model\n",
    "\n",
    "from simpletransformers.classification import ClassificationModel, ClassificationArgs\n",
    "\n",
    "\"\"\"\n",
    "The following set of hyperparameters are the optimized hyperparameters\n",
    "\"\"\"\n",
    "model_args = ClassificationArgs()\n",
    "model_args.train_batch_size = 64\n",
    "model_args.learning_rate = 0.0000215\n",
    "model_args.max_seq_length = 256\n",
    "model_args.num_train_epochs = 42\n",
    "model_args.overwrite_output_dir = True\n",
    "\n",
    "model = ClassificationModel(\n",
    "        'albert', \n",
    "        'albert-base-v2', \n",
    "        num_labels=2, \n",
    "        use_cuda=True, \n",
    "        args=model_args\n",
    "    )\n",
    "\n",
    "# Training the model\n",
    "step, tr_loss = model.train_model(train_df)\n",
    "\n",
    "# Evaluation during training\n",
    "result, model_outputs, wrong_preds = model.eval_model(val_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-relaxation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Model\n",
    "\n",
    "# Loading the test dataset\n",
    "test = pd.read_excel('../dataset/Project_Datasets/english_test_with_labels.xlsx')\n",
    "\n",
    "\"\"\"\n",
    "Predict function \n",
    "\n",
    "Input:\n",
    "    input_data: The test dataset to be used for evaluation\n",
    "    \n",
    "Output:\n",
    "    List of lists with each line in the form of [tweet, ground_truth, prediction]\n",
    "        for line in the test dataset excel\n",
    "\"\"\"\n",
    "def predict(input_data):\n",
    "    output = []\n",
    "    for index, row in input_data.iterrows():        \n",
    "        tweets = cleanText(row[1])\n",
    "        gt_label= row[2]\n",
    "        predictions, raw_outputs = model.predict([tweets])\n",
    "        output.append([tweets, gt_label , predictions])\n",
    "    return output\n",
    "\n",
    "pred_output = predict(test)\n",
    "\n",
    "print(pred_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the prediction output to a file\n",
    "\n",
    "\"\"\"\n",
    "This code will save the prediction output into a text file\n",
    "\n",
    "Output:\n",
    "    .txt file with each line as an ouput from evaluating the model \n",
    "        in the format of [tweet, ground_truth, prediction]\n",
    "\"\"\"\n",
    "\n",
    "with open('pred_output.txt', 'w') as f:\n",
    "    for item in pred_output:\n",
    "        f.write(\"%s - %s - %d\\n\" %(item[0], item[1], item[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-solution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metric calculation\n",
    "\n",
    "\"\"\"\n",
    "This function will calculate the various evaluation metrics\n",
    "\n",
    "Input:\n",
    "    lists: list of lists that is output from the predict() function\n",
    "\n",
    "Output:\n",
    "    TP: True positive\n",
    "    TN: True negative\n",
    "    FP: False positive\n",
    "    FN: False negative\n",
    "    accuracy: calculated as (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision: calculated as TP / (TP + FP)\n",
    "    recall: calculated as TP / (TP + FN)\n",
    "\"\"\"\n",
    "\n",
    "def eval_metric_calc(lists):\n",
    "    precision = 0\n",
    "    recall = 0\n",
    "    accuracy = 0\n",
    "    TP = 0 \n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "    \n",
    "    for i in range(len(lists)):\n",
    "        if lists[i][1] == \"fake\" and lists[i][2] == 0:\n",
    "            TP += 1\n",
    "        elif lists[i][1] == \"fake\" and lists[i][2] == 1:\n",
    "            FN += 1\n",
    "        elif lists[i][1] == \"real\" and lists[i][2] == 0:\n",
    "            FP += 1\n",
    "        else:\n",
    "            TN += 1\n",
    "            \n",
    "    accuracy = (TP + TN) / (TP + FP + FN + TN)\n",
    "    precision = TP / (TP + FP)\n",
    "    recall = TP / (TP + FN)\n",
    "    \n",
    "    return TP, TN, FP, FN, accuracy, precision, recall\n",
    "\n",
    "TP, TN, FP, FN, accuracy, precision, recall = eval_metric_calc(pred_output)\n",
    "\n",
    "print(\"accuracy : \", accuracy, \"precision : \", precision, \"recall : \", recall)\n",
    "print(\"TP : \", TP, \"TN : \", TN, \"FP : \", FP, \"FN : \", FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recorded-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Results\n",
    "\n",
    "labels = ['True Positive', 'True Negative']\n",
    "ALBERT = [TP, TN] # Metric from Model evaluation\n",
    "SVM = [1039, 958] # Hardcoded value obtained from supervised baseline\n",
    "\n",
    "x = np.arange(len(labels))  # The label locations\n",
    "width = 0.15  # The width of the bars\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "albert = ax.bar(x - width/2, ALBERT, width, label='ALBERT')\n",
    "svm = ax.bar(x + width/2, SVM, width, label='SVM')\n",
    "\n",
    "# Add text for labels, title and custom x-axis tick labels\n",
    "ax.set_ylabel('Number')\n",
    "#ax.set_title('Correctly Classified Tweets')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylim([0,1200])\n",
    "ax.legend()\n",
    "\n",
    "\"\"\"\n",
    "This function will label the height of the histogram\n",
    "\n",
    "Input:\n",
    "    rects: the bar graph to be labeled\n",
    "\n",
    "Output:\n",
    "    label for the height of the bar graph\n",
    "\"\"\"\n",
    "def autolabel(rects):\n",
    "    # Attach a text label above each bar in *rects*, displaying its height\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.annotate('{}'.format(height),\n",
    "                    xy=(rect.get_x() + rect.get_width() / 2, height),\n",
    "                    xytext=(0, 3),  # 3 points vertical offset\n",
    "                    textcoords=\"offset points\",\n",
    "                    ha='center', va='bottom')\n",
    "\n",
    "\n",
    "autolabel(albert)\n",
    "autolabel(svm)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
